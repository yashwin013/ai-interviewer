{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829a2e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaurav.sharma\\OneDrive - Uneecops Technologies Ltd\\Desktop\\ai-interviewer\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "c:\\Users\\gaurav.sharma\\OneDrive - Uneecops Technologies Ltd\\Desktop\\ai-interviewer\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:2041: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Yashwin Verma', 'phone': '+91 6392256489', 'linkedin': 'linkedin.com/YashwinVerma', 'github': 'github.com/yashwin013', 'skills': ['Java', 'Python', 'C', 'C++', 'DBMS', 'JavaScript', 'HTML/CSS', 'MERN', 'Flask', 'WordPress', 'TensorFlow', 'Keras', 'Socket.io', 'TailwindCSS', 'Mongoose', 'Generative AI', 'LLM', 'Spring Boot', 'Angular', 'Git', 'AWS', 'Google Cloud Platform', 'Microsoft Azure', 'MongoDB', 'Cloudinary', 'Postman', 'Jerkins', 'CI/CD pipeline', 'Veracode'], 'experience': 'Full Stack Developer Intern, Hapticware Jan 2025 ‚Äì Apr 2025 ‚Ä¢ Designed and maintained scalable backend services for a financial document analysis platform using the MERN stack, enabling automated processing of 200+ quarterly reports weekly. ‚Ä¢ Engineered secure RESTful APIs and optimized MongoDB integration, boosting data retrieval speed and system reliability by 35%. ‚Ä¢ Collaborated with AI teams to integrate LLM-based analytics into the frontend, reducing response latency by 40% and enhancing the platform experience for users. Web Development Intern, GetCurious (formerly UserStudy) ‚Äì Bengaluru, India Sep 2023 ‚Äì Nov 2023 ‚Ä¢ Built dynamic and responsive applications using React, Angular and Django, reducing development time by 15%. ‚Ä¢ Collaborated with team streamlining code management with Git and reducing integration issues by 30%.'}\n"
     ]
    }
   ],
   "source": [
    "# Rough Work\n",
    "\n",
    "# LLM to extract text\n",
    "\n",
    "\n",
    "f1 = {\n",
    "  \"message\": \"Resume uploaded and text extracted successfully.\",\n",
    "  \"resumeProfile\": {\n",
    "    \"extracted_text\": \"Yashwin Verma yashwinverma13@gmail.com | +91 6392256489 | linkedin.com/YashwinVerma | github.com/yashwin013 Professional Summary A Computer Science graduate specializing in AI/ML and backend development. Proficient in building scalable APIs with the MERN stack and developing high-accuracy deep learning models for tasks like computer vision and data analysis. Skilled in Python and Java, I am eager to contribute to a challenging backend or AI/ML role where I can build innovative and efficient solutions. Education Vellore Institute of Technology Sep 2021 ‚Äì May 2025 Bachelor of Technology in Computer Science Delhi Public School, Kalyanpur Jun 2021 Intermediate (CBSE) Experience Full Stack Developer Intern, Hapticware Jan 2025 ‚Äì Apr 2025 ‚Ä¢ Designed and maintained scalable backend services for a financial document analysis platform using the MERN stack, enabling automated processing of 200+ quarterly reports weekly. ‚Ä¢ Engineered secure RESTful APIs and optimized MongoDB integration, boosting data retrieval speed and system reliability by 35%. ‚Ä¢ Collaborated with AI teams to integrate LLM-based analytics into the frontend, reducing response latency by 40% and enhancing the platform experience for users. Web Development Intern, GetCurious (formerly UserStudy) ‚Äì Bengaluru, India Sep 2023 ‚Äì Nov 2023 ‚Ä¢ Built dynamic and responsive applications using React, Angular and Django, reducing development time by 15%. ‚Ä¢ Collaborated with team streamlining code management with Git and reducing integration issues by 30%. Projects Real-Time Messaging Application using MERN & Socket.io ‚Ä¢ Designed to enable secure, low-latency real-time communication between users. ‚Ä¢ Developed a full-stack chat platform using MERN stack, Socket.io, and TailwindCSS with JWT-based authentication, CI/CD deployment, and Cloudinary integration for image storage. ‚Ä¢ Improved API response times by 35%, reduced message delivery latency, and achieved 99.9% uptime with seamless real-time updates. Brain Tumor Detection using Convolutional Neural Networks ‚Ä¢ Aimed to automate brain tumor classification from MRI scans using deep learning. ‚Ä¢ Built and trained a CNN model with TensorFlow, integrating data preprocessing pipelines (normalization, resizing, and augmentation) and performing hyperparameter tuning for accuracy optimization. ‚Ä¢ Achieved 97% classification accuracy and improved training efficiency by 15%, ensuring more robust feature extraction and prediction reliability. Underwater Microplastic Pollution Hotspot Management ‚Ä¢ Developed to detect underwater plastic pollution and predict microplastic density for targeted cleanup operations. ‚Ä¢ Devised a YOLOv8-based object detection model trained on underwater datasets and integrated NOAA environmental data (temperature, salinity, currents) to estimate microplastic spread. Built an AI-driven density estimation system for mapping hotspots. ‚Ä¢ Reached 92.5% detection accuracy, improved pollution mapping precision by 23%, and optimized cleanup resource allocation by 47%, supporting sustainable ocean management. Skills Languages: Java, Python, C, C++, DBMS , JavaScript, HTML/CSS Frameworks: MERN, Flask, WordPress, TensorFlow, Keras, Socket.io, TailwindCSS, Mongoose, Generative AI, LLM, Spring Boot, Angular Developer Tools: Git, AWS , Google Cloud Platform, Microsoft Azure, MongoDB, Cloudinary, Postman, Jerkins, CI/CD pipeline, Veracode\",\n",
    "    \"chunks\": [\n",
    "      \"Yashwin Verma yashwinverma13@gmail.com | +91 6392256489 | linkedin.com/YashwinVerma | github.com/yashwin013 Professional Summary A Computer Science graduate specializing in AI/ML and backend development. Proficient in building scalable APIs with the MERN stack and developing high-accuracy deep learning models for tasks like computer vision and data analysis. Skilled in Python and Java, I am eager to contribute to a challenging backend or AI/ML role where I can build innovative and efficient solutions. Education Vellore Institute of Technology Sep 2021 ‚Äì May 2025 Bachelor of Technology in Computer Science Delhi Public School, Kalyanpur Jun 2021 Intermediate (CBSE) Experience Full Stack Developer Intern, Hapticware Jan 2025 ‚Äì Apr 2025 ‚Ä¢ Designed and maintained scalable backend services for a\",\n",
    "      \"Intern, Hapticware Jan 2025  Apr 2025 ‚Ä¢ Designed and maintained scalable backend services for a financial document analysis platform using the MERN stack, enabling automated processing of 200+ quarterly reports weekly. ‚Ä¢ Engineered secure RESTful APIs and optimized MongoDB integration, boosting data retrieval speed and system reliability by 35%. ‚Ä¢ Collaborated with AI teams to integrate LLM-based analytics into the frontend, reducing response latency by 40% and enhancing the platform experience for users. Web Development Intern, GetCurious (formerly UserStudy) ‚Äì Bengaluru, India Sep 2023 ‚Äì Nov 2023 ‚Ä¢ Built dynamic and responsive applications using React, Angular and Django, reducing development time by 15%. ‚Ä¢ Collaborated with team streamlining code management with Git and reducing\",\n",
    "      \"time by 15%. ‚Ä¢ Collaborated with team streamlining code management with Git and reducing integration issues by 30%. Projects Real-Time Messaging Application using MERN & Socket.io ‚Ä¢ Designed to enable secure, low-latency real-time communication between users. ‚Ä¢ Developed a full-stack chat platform using MERN stack, Socket.io, and TailwindCSS with JWT-based authentication, CI/CD deployment, and Cloudinary integration for image storage. ‚Ä¢ Improved API response times by 35%, reduced message delivery latency, and achieved 99.9% uptime with seamless real-time updates. Brain Tumor Detection using Convolutional Neural Networks ‚Ä¢ Aimed to automate brain tumor classification from MRI scans using deep learning. ‚Ä¢ Built and trained a CNN model with TensorFlow, integrating data preprocessing\",\n",
    "      \"deep learning. ‚Ä¢ Built and trained a CNN model with TensorFlow, integrating data preprocessing pipelines (normalization, resizing, and augmentation) and performing hyperparameter tuning for accuracy optimization. ‚Ä¢ Achieved 97% classification accuracy and improved training efficiency by 15%, ensuring more robust feature extraction and prediction reliability. Underwater Microplastic Pollution Hotspot Management ‚Ä¢ Developed to detect underwater plastic pollution and predict microplastic density for targeted cleanup operations. ‚Ä¢ Devised a YOLOv8-based object detection model trained on underwater datasets and integrated NOAA environmental data (temperature, salinity, currents) to estimate microplastic spread. Built an AI-driven density estimation system for mapping hotspots. ‚Ä¢ Reached 92.5%\",\n",
    "      \"spread. Built an AI-driven density estimation system for mapping hotspots. ‚Ä¢ Reached 92.5% detection accuracy, improved pollution mapping precision by 23%, and optimized cleanup resource allocation by 47%, supporting sustainable ocean management. Skills Languages: Java, Python, C, C++, DBMS , JavaScript, HTML/CSS Frameworks: MERN, Flask, WordPress, TensorFlow, Keras, Socket.io, TailwindCSS, Mongoose, Generative AI, LLM, Spring Boot, Angular Developer Tools: Git, AWS , Google Cloud Platform, Microsoft Azure, MongoDB, Cloudinary, Postman, Jerkins, CI/CD pipeline, Veracode\"\n",
    "    ],\n",
    "    \"file_path\": \"C:\\\\Users\\\\Yashwin\\\\Documents\\\\Projects\\\\AI-Powered Mock Interviewer\\\\backend\\\\uploads\\\\resumes\\\\e288368d-94f8-456b-bc62-21b3e82c97b8.pdf\"\n",
    "  }\n",
    "    }\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class ResumeProfileExtraction(BaseModel):\n",
    "    name: Optional[str] = Field(description = \"Name of the candidate.\")\n",
    "    phone: Optional[str] = Field(description = \"Phone number of the candidate.\")\n",
    "    linkedin: Optional[str] = Field(description = \"LinkedIn Profile of the candidate.\")\n",
    "    github: Optional[str] = Field(description = \"GitHub link of the candidate.\")\n",
    "    skills: Optional[list[str]] = Field(description = \"Skills of the candidate.\")\n",
    "    experience: Optional[str] = Field(description = \"Candidate's work experience.\")\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\")\n",
    "response = llm.with_structured_output(ResumeProfileExtraction)\n",
    "\n",
    "def extract_fields_llm(text: str) -> ResumeProfileExtraction:\n",
    "    prompt = f\"\"\"\n",
    "                Extract the following fields from the object(s) you receive : \n",
    "                \n",
    "                - Full name\n",
    "                - Phone Number\n",
    "                - LinkedIn\n",
    "                - GitHub\n",
    "                - Skills\n",
    "                - Experience\n",
    "\n",
    "                Text:\n",
    "                {text}\n",
    "               \"\"\"\n",
    "\n",
    "    return response.invoke(prompt)\n",
    "\n",
    "fields = extract_fields_llm(f1[\"resumeProfile\"])\n",
    "print(fields.model_dump())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908303d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run pipeline from: 1) External JSON  2) PDF file\n",
      "Using sample placeholder. Replace with your `f1` object or path to your JSON file.\n",
      "[extract_from_external_json] Running structured LLM extraction...\n",
      "\n",
      "[run_interview_loop] Starting interview for John (Mid)\n",
      "[run_interview_loop] Total Questions: 10\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'profile_context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 497\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPDF:\u001b[39m\u001b[33m\"\u001b[39m, state.pdf_path_out)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 474\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    471\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m    472\u001b[39m             resume_json = json.load(fh)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     state = \u001b[43morchestrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_full_pipeline_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    477\u001b[39m     pdf_path = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPath to resume PDF: \u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 418\u001b[39m, in \u001b[36mOrchestrator.run_full_pipeline_from_json\u001b[39m\u001b[34m(self, resume_json)\u001b[39m\n\u001b[32m    415\u001b[39m state.vectorstore = x[\u001b[33m\"\u001b[39m\u001b[33mvectorstore\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Interview loop\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_interview_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# Assessment\u001b[39;00m\n\u001b[32m    421\u001b[39m state.assessment = \u001b[38;5;28mself\u001b[39m.generate_assessment(state)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 296\u001b[39m, in \u001b[36mOrchestrator.run_interview_loop\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m state.questions_asked < state.max_questions:\n\u001b[32m    285\u001b[39m \n\u001b[32m    286\u001b[39m     \u001b[38;5;66;03m# Build chat-history for LLM\u001b[39;00m\n\u001b[32m    287\u001b[39m     chat_history_text = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    288\u001b[39m         [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInterviewer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqa[\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCandidate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqa[\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m qa \u001b[38;5;129;01min\u001b[39;00m state.transcript]\n\u001b[32m    289\u001b[39m     )\n\u001b[32m    291\u001b[39m     inputs = {\n\u001b[32m    292\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mseniority_level\u001b[39m\u001b[33m\"\u001b[39m: state.profile[\u001b[33m\"\u001b[39m\u001b[33mseniority_level\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    293\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtotal_questions_asked\u001b[39m\u001b[33m\"\u001b[39m: state.questions_asked,\n\u001b[32m    294\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_questions\u001b[39m\u001b[33m\"\u001b[39m: state.max_questions,\n\u001b[32m    295\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m: chat_history_text,\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mprofile_context\u001b[39m\u001b[33m\"\u001b[39m : \u001b[43mprofile_context\u001b[49m\n\u001b[32m    297\u001b[39m     }\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# Generate question\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'profile_context' is not defined"
     ]
    }
   ],
   "source": [
    "# Code using extracted information from pdf externally(Thereby reducing token usage on llm and agent) \n",
    "# ------ Currently in use(10th December)\n",
    "\n",
    "\"\"\"\n",
    "orchestrator_from_json.py\n",
    "Full merged orchestrator that uses externally-parsed resume JSON (f1) as input.\n",
    "Features:\n",
    "- LLM-based structured extraction from provided resume text\n",
    "- FAISS vectorstore from provided chunks\n",
    "- TTS (gTTS) + STT (sounddevice + SpeechRecognition) optional per-question\n",
    "- Interview loop, structured assessment, PDF export\n",
    "- Two runners: from JSON (preferred) and from PDF (fallback)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import traceback\n",
    "\n",
    "# LLM / embeddings / chain primitives\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.documents import Document\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "except Exception as e:\n",
    "    print(\"Warning: LangChain/OpenAI imports failed. Install required packages if you plan to run LLM steps.\")\n",
    "    print(\"Import error:\", e)\n",
    "\n",
    "# Audio & PDF generation\n",
    "AUDIO_AVAILABLE = True\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    from playsound3 import playsound\n",
    "    import speech_recognition as sr\n",
    "    import sounddevice as sd\n",
    "    import numpy as np\n",
    "    from scipy.io.wavfile import write\n",
    "except Exception as e:\n",
    "    AUDIO_AVAILABLE = False\n",
    "    print(\"Audio libs missing or failed to import ‚Äî audio features disabled. Error:\", e)\n",
    "\n",
    "try:\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "    from reportlab.lib.styles import getSampleStyleSheet\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.lib.units import inch\n",
    "except Exception as e:\n",
    "    print(\"Warning: reportlab not installed. PDF generation will fail. Error:\", e)\n",
    "\n",
    "# -------------------------\n",
    "# User-provided structured extraction schema (from your snippet)\n",
    "# -------------------------\n",
    "class ResumeProfileExtraction(BaseModel):\n",
    "    name: Optional[str] = Field(description=\"Name of the candidate.\")\n",
    "    phone: Optional[str] = Field(description=\"Phone number of the candidate.\")\n",
    "    linkedin: Optional[str] = Field(description=\"LinkedIn Profile of the candidate.\")\n",
    "    github: Optional[str] = Field(description=\"GitHub link of the candidate.\")\n",
    "    skills: Optional[List[str]] = Field(description=\"Skills of the candidate.\")\n",
    "    experience: Optional[str] = Field(description=\"Candidate's work experience.\")\n",
    "\n",
    "\n",
    "# Structured assessment schema (same as before)\n",
    "class InterviewAssessment(BaseModel):\n",
    "    candidate_score_percent: str = Field(description=\"Score for the candidate out of 100.\")\n",
    "    hiring_recommendation: str = Field(description=\"Hiring recommendation: 'Definitely Hire!', 'Proceed with caution', 'Dont hire'\")\n",
    "    strengths: List[str] = Field(description=\"Strengths the candidate displayed.\")\n",
    "    improvement_areas: List[str] = Field(description=\"Improvement areas.\")\n",
    "    next_steps: str = Field(description=\"Suggested next steps.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Orchestrator state and prompts\n",
    "# -------------------------\n",
    "class InterviewState(BaseModel):\n",
    "    source_id: str  # \"JSON\" or PDF path\n",
    "    profile: Optional[Dict[str, Any]] = None\n",
    "    vectorstore: Optional[Any] = None\n",
    "    transcript: List[Dict[str, str]] = []\n",
    "    questions_asked: int = 0\n",
    "    max_questions: int = 0\n",
    "    assessment: Optional[Dict[str, Any]] = None\n",
    "    pdf_path_out: Optional[str] = None\n",
    "\n",
    "\n",
    "# Interviewer prompt (uses prompt template variables)\n",
    "interviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    The candidate has a seniority of: {seniority_level}.\n",
    "\n",
    "    YOUR PRIMARY GOAL:\n",
    "    - Conduct an interview of exactly {max_questions} questions.\n",
    "    - Match question difficulty to seniority level:\n",
    "        Fresher -> conceptual basics\n",
    "        Junior -> practical + scenario\n",
    "        Mid-level -> deeper practical reasoning\n",
    "        Senior -> architecture & ownership\n",
    "    SECONDARY GOAL:\n",
    "    - Ask a balanced variety: experience-based, skill-based, behavioral.\n",
    "    RULE:\n",
    "    - If total_questions_asked equals 0, ask an introductory question (e.g., \"Tell me about yourself.\")\n",
    "    \"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    INTERVIEW STATUS:\n",
    "    Questions Asked: {total_questions_asked} / {max_questions}\n",
    "\n",
    "    TRANSCRIPT SO FAR:\n",
    "    {chat_history}\n",
    "\n",
    "    PROFILE CONTEXT:\n",
    "    {profile_context}\n",
    "\n",
    "    INSTRUCTION:\n",
    "    Generate *only* the next question. Avoid repeating earlier questions. Cover a new area if possible.\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# Assessment prompt\n",
    "assessment_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    You are an experienced Hiring Manager and Technical Assessor. Analyze the interview transcript and the candidate profile and generate a structured assessment JSON conforming to the InterviewAssessment schema.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    CANDIDATE PROFILE:\n",
    "    {profile_doc}\n",
    "\n",
    "    --- COMPLETE INTERVIEW TRANSCRIPT ---\n",
    "    {chat_history}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Orchestrator implementation\n",
    "# -------------------------\n",
    "class Orchestrator:\n",
    "    def __init__(self, llm: Optional[ChatOpenAI] = None, embeddings: Optional[OpenAIEmbeddings] = None, use_audio: bool = False):\n",
    "        self.llm = llm or (ChatOpenAI(model=\"gpt-4o-mini\") if \"ChatOpenAI\" in globals() else None)\n",
    "        self.embeddings = embeddings or (OpenAIEmbeddings() if \"OpenAIEmbeddings\" in globals() else None)\n",
    "        self.use_audio = use_audio and AUDIO_AVAILABLE\n",
    "        self.interviewer_prompt = interviewer_prompt # Attaching the interviewer prompt\n",
    "        self.assessment_prompt = assessment_prompt # Attaching the assessment prompt\n",
    "\n",
    "    # ---------- Audio helpers ----------\n",
    "    def _speak(self, text: str):\n",
    "        if not (AUDIO_AVAILABLE and self.use_audio):\n",
    "            return\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            try:\n",
    "                tts = gTTS(text=text, lang=\"en\")\n",
    "                tts.save(tmp.name)\n",
    "                playsound(tmp.name)\n",
    "            finally:\n",
    "                try:\n",
    "                    os.remove(tmp.name)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    def _listen_for_answer(self, duration: int = 8, sample_rate: int = 16000, channels: int = 1) -> Optional[str]:\n",
    "        if not (AUDIO_AVAILABLE and self.use_audio):\n",
    "            return None\n",
    "        try:\n",
    "            print(f\"[STT] Recording for {duration}s...\")\n",
    "            recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels, dtype='float64')\n",
    "            sd.wait()\n",
    "            audio_int16 = np.int16(recording * 32767)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "                write(tmp.name, sample_rate, audio_int16)\n",
    "                tmpfile = tmp.name\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.AudioFile(tmpfile) as source:\n",
    "                audio = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "            try:\n",
    "                os.remove(tmpfile)\n",
    "            except Exception:\n",
    "                pass\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(\"[STT] Error:\", e)\n",
    "            return None\n",
    "\n",
    "    # ---------- LLM-based structured extraction from text using provided schema ----------\n",
    "    def _llm_extract_profile(self, text: str) -> ResumeProfileExtraction:\n",
    "        if not self.llm:\n",
    "            raise RuntimeError(\"LLM not configured for profile extraction.\")\n",
    "        structured = self.llm.with_structured_output(ResumeProfileExtraction)\n",
    "        prompt = f\"\"\"\n",
    "Extract the following fields as clearly as possible from the text below:\n",
    "- Full name\n",
    "- Phone Number\n",
    "- LinkedIn\n",
    "- GitHub\n",
    "- Skills (as a list)\n",
    "- Experience (short summary)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "        return structured.invoke(prompt)\n",
    "\n",
    "    # ---------- Build vectorstore from provided chunks ----------\n",
    "    def _build_vectorstore_from_chunks(self, chunks: List[str]):\n",
    "        docs = [Document(page_content=c, metadata={\"source\": \"external_chunk\", \"chunk_index\": i}) for i, c in enumerate(chunks)]\n",
    "        if not self.embeddings:\n",
    "            print(\"[_build_vectorstore_from_chunks] No embeddings configured; skipping vectorstore build.\")\n",
    "            return None\n",
    "        try:\n",
    "            vs = FAISS.from_documents(documents=docs, embedding=self.embeddings)\n",
    "            return vs\n",
    "        except Exception as e:\n",
    "            print(\"[_build_vectorstore_from_chunks] FAISS build failed:\", e)\n",
    "            return None\n",
    "\n",
    "    # ---------- New: Use external JSON (f1) as input ----------\n",
    "    def extract_from_external_json(self, resume_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # resume_json shape expected like your f1\n",
    "        if \"resumeProfile\" not in resume_json:\n",
    "            raise ValueError(\"resume_json must contain 'resumeProfile' key.\")\n",
    "\n",
    "        rp = resume_json[\"resumeProfile\"]\n",
    "        extracted_text = rp.get(\"extracted_text\", \"\")\n",
    "        chunks = rp.get(\"chunks\", [extracted_text])  # fallback to full text chunk if no chunks provided\n",
    "\n",
    "        # LLM structured extraction from the full extracted_text\n",
    "        try:\n",
    "            print(\"[extract_from_external_json] Running structured LLM extraction...\")\n",
    "            structured_result = self._llm_extract_profile(extracted_text)\n",
    "        except Exception as e:\n",
    "            print(\"[extract_from_external_json] Structured extraction failed:\", e)\n",
    "            # Build a minimal profile fallback\n",
    "            structured_result = ResumeProfileExtraction(name=None, phone=None, linkedin=None, github=None, skills=None, experience=None)\n",
    "\n",
    "        # Map to internal profile shape\n",
    "        name = (structured_result.name or \"\").strip()\n",
    "        first, last = (name.split(\" \", 1) + [\"\"])[:2] if name else (\"\", \"\")\n",
    "        profile = {\n",
    "            \"candidate_first_name\": first,\n",
    "            \"candidate_last_name\": last,\n",
    "            \"candidate_email\": rp.get(\"email\", \"\") or \"\",  # optional - your f1 may not provide explicit email field\n",
    "            \"candidate_linkedin\": structured_result.linkedin or rp.get(\"linkedin\", \"\"),\n",
    "            \"experience\": structured_result.experience or \"\",\n",
    "            \"skills\": structured_result.skills or [],\n",
    "            \"seniority_level\": \"Mid\"  # default; you could infer from experience/years if desired\n",
    "        }\n",
    "\n",
    "        vectorstore = self._build_vectorstore_from_chunks(chunks)\n",
    "        return {\"profile\": profile, \"vectorstore\": vectorstore, \"raw_chunks\": chunks, \"structured_result\": structured_result}\n",
    "\n",
    "    # ---------- (Optional) Small PDF fallback extractor if you still want to parse PDF ----------\n",
    "    def extract_from_pdf(self, pdf_path: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            resume_text = \"\\n\".join([p.page_content for p in pages])\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load PDF: {e}\")\n",
    "        # minimal chunks: split by pages\n",
    "        chunks = [p.page_content for p in pages]\n",
    "        return self.extract_from_external_json({\"resumeProfile\": {\"extracted_text\": resume_text, \"chunks\": chunks}})\n",
    "\n",
    "    # ---------- Interview loop (uses vectorstore for RAG context) ----------\n",
    "    def run_interview_loop(self, state: InterviewState):\n",
    "        \"\"\"Interview loop with TTS (gTTS) + STT (sounddevice) + optional typed answers.\"\"\"\n",
    "\n",
    "        # Determine max questions based on seniority\n",
    "        # Kept it experimental => can be changed accordingly\n",
    "        seniority = state.profile.get(\"seniority_level\", \"mid\").lower()\n",
    "        if seniority == \"fresher\":\n",
    "            max_q = 5\n",
    "        elif seniority == \"junior\":\n",
    "            max_q = 7\n",
    "        else:\n",
    "            max_q = 10\n",
    "        state.max_questions = max_q # Pushing max number of questions in state\n",
    "\n",
    "        print(f\"\\n[run_interview_loop] Starting interview for {state.profile.get('candidate_first_name', 'Candidate')} ({state.profile.get('seniority_level')})\")\n",
    "        print(f\"[run_interview_loop] Total Questions: {state.max_questions}\\n\")\n",
    "\n",
    "        while state.questions_asked < state.max_questions:\n",
    "\n",
    "            # Build chat-history for LLM\n",
    "            chat_history_text = \"\\n\".join(\n",
    "                [f\"Interviewer: {qa['q']}\\nCandidate: {qa['a']}\" for qa in state.transcript]\n",
    "            )\n",
    "\n",
    "            inputs = {\n",
    "                \"seniority_level\": state.profile[\"seniority_level\"],\n",
    "                \"total_questions_asked\": state.questions_asked,\n",
    "                \"max_questions\": state.max_questions,\n",
    "                \"chat_history\": chat_history_text,\n",
    "                \"profile_context\" : profile_context\n",
    "            }\n",
    "\n",
    "            # Generate question\n",
    "            try:\n",
    "                interview_chain = self.interviewer_prompt | self.llm | StrOutputParser()\n",
    "                question = interview_chain.invoke(inputs)\n",
    "            except Exception as e:\n",
    "                print(\"\\n================ REAL LLM ERROR (QUESTION GENERATION) ================\")\n",
    "                traceback.print_exc()\n",
    "                print(\"================ END ERROR ================\\n\")\n",
    "                question = f\"[Fallback] Please tell me about your experience. (Q{state.questions_asked+1})\" \n",
    "            qnum = state.questions_asked + 1 # Incrementing the question count by 1\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"‚ùì Question {qnum}/{state.max_questions}\")\n",
    "            print(\"Interviewer:\", question)\n",
    "\n",
    "            # Speak question via TTS\n",
    "            if self.use_audio:\n",
    "                try:\n",
    "                    self._speak(question)\n",
    "                except Exception as e:\n",
    "                    print(\"[TTS Error]:\", e)\n",
    "            \n",
    "            # After speaking question, the user will have 2 options => either to type the answer, or to speak the answer.\n",
    "            # ---------------------------------------------\n",
    "            # USER CHOICE: SPEAK or TYPE\n",
    "            # ---------------------------------------------\n",
    "            print(\"\\nHow would you like to answer?\")\n",
    "            print(\"1) Speak into microphone\")\n",
    "            print(\"2) Type answer\")\n",
    "            method = input(\"Choose 1 or 2: \").strip()\n",
    "\n",
    "            answer = None\n",
    "\n",
    "            if method == \"1\" and AUDIO_AVAILABLE:\n",
    "                print(\"\\nüé§ Recording your answer...\")\n",
    "                answer = self._listen_for_answer(duration=12)\n",
    "\n",
    "                if not answer:\n",
    "                    print(\"‚ö†Ô∏è Speech recognition failed.\")\n",
    "                    answer = input(\"Please type your answer instead: \").strip()\n",
    "\n",
    "            else:\n",
    "                answer = input(\"\\nType your answer: \").strip()\n",
    "\n",
    "            if answer.lower() in (\"exit\", \"quit\"):\n",
    "                print(\"\\nüõë Interview Stopped.\")\n",
    "                break\n",
    "\n",
    "            # Save to transcript\n",
    "            state.transcript.append({\"q\": question, \"a\": answer})\n",
    "            state.questions_asked += 1\n",
    "\n",
    "        print(\"\\nInterview completed.\")\n",
    "        return state\n",
    "\n",
    "    # ---------- Assessment (route dict -> prompt -> structured LLM) ----------\n",
    "    def generate_assessment(self, state: InterviewState) -> Dict[str, Any]:\n",
    "        if not self.llm:\n",
    "            raise RuntimeError(\"LLM not configured for assessment.\")\n",
    "\n",
    "        structured_assessor = self.llm.with_structured_output(InterviewAssessment)\n",
    "        chain = assessment_prompt | structured_assessor\n",
    "\n",
    "        final_inputs = {\n",
    "            \"difficulty_level\": state.profile.get(\"seniority_level\", \"Mid\"),\n",
    "            \"profile_doc\": json.dumps(state.profile, indent=2),\n",
    "            \"chat_history\": \"\\n\".join([f\"Q: {t['q']}\\nA: {t['a']}\" for t in state.transcript])\n",
    "        }\n",
    "\n",
    "        print(\"\\n[generate_assessment] Invoking assessor chain...\")\n",
    "        try:\n",
    "            assessment_obj = chain.invoke(final_inputs)  # correct: passes dict to prompt template\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Assessment generation failed: {e}\")\n",
    "\n",
    "        assessment_dict = {\n",
    "            \"candidate_score_percent\": assessment_obj.candidate_score_percent,\n",
    "            \"hiring_recommendation\": assessment_obj.hiring_recommendation,\n",
    "            \"strengths\": assessment_obj.strengths,\n",
    "            \"improvement_areas\": assessment_obj.improvement_areas,\n",
    "            \"next_steps\": assessment_obj.next_steps\n",
    "        }\n",
    "        return assessment_dict\n",
    "\n",
    "    # ---------- PDF export ----------\n",
    "    def generate_pdf(self, state: InterviewState, filename: Optional[str] = None) -> str:\n",
    "        if filename is None:\n",
    "            filename = f\"candidate_assessment_{state.profile.get('candidate_first_name','candidate')}.pdf\"\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        title = Paragraph(f\"<b>Final Candidate Assessment for {state.profile.get('candidate_first_name','')} {state.profile.get('candidate_last_name','')}</b>\", styles[\"Title\"])\n",
    "        story.append(title)\n",
    "        story.append(Spacer(1, 0.25 * inch))\n",
    "        story.append(Paragraph(f\"<b>Overall Score:</b> {state.assessment.get('candidate_score_percent','N/A')}\", styles[\"Normal\"]))\n",
    "        story.append(Paragraph(f\"<b>Recommendation:</b> {state.assessment.get('hiring_recommendation','N/A')}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.15 * inch))\n",
    "        story.append(Paragraph(\"<b>Strengths:</b>\", styles[\"Heading3\"]))\n",
    "        for s in state.assessment.get(\"strengths\", []):\n",
    "            story.append(Paragraph(f\"‚Ä¢ {s}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.15 * inch))\n",
    "        story.append(Paragraph(\"<b>Improvement Areas:</b>\", styles[\"Heading3\"]))\n",
    "        for i in state.assessment.get(\"improvement_areas\", []):\n",
    "            story.append(Paragraph(f\"‚Ä¢ {i}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.2 * inch))\n",
    "        story.append(Paragraph(\"<b>Next Steps:</b>\", styles[\"Heading3\"]))\n",
    "        story.append(Paragraph(state.assessment.get(\"next_steps\", \"\"), styles[\"Normal\"]))\n",
    "\n",
    "        pdf = SimpleDocTemplate(filename, pagesize=letter)\n",
    "        pdf.build(story)\n",
    "        print(f\"[generate_pdf] PDF saved: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    # ---------- Full-run entrypoints ----------\n",
    "    def run_full_pipeline_from_json(self, resume_json: Dict[str, Any]) -> InterviewState:\n",
    "        x = self.extract_from_external_json(resume_json)\n",
    "        state = InterviewState(source_id=\"EXTERNAL_JSON\")\n",
    "        state.profile = x[\"profile\"]\n",
    "        state.vectorstore = x[\"vectorstore\"]\n",
    "\n",
    "        # Interview loop\n",
    "        state = self.run_interview_loop(state)\n",
    "\n",
    "        # Assessment\n",
    "        state.assessment = self.generate_assessment(state)\n",
    "\n",
    "        # PDF\n",
    "        state.pdf_path_out = self.generate_pdf(state)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def run_full_pipeline_from_pdf(self, pdf_path: str) -> InterviewState:\n",
    "        x = self.extract_from_pdf(pdf_path)\n",
    "        state = InterviewState(source_id=pdf_path)\n",
    "        state.profile = x[\"profile\"]\n",
    "        state.vectorstore = x[\"vectorstore\"]\n",
    "\n",
    "        # Interview loop\n",
    "        state = self.run_interview_loop(state)\n",
    "\n",
    "        # Assessment\n",
    "        state.assessment = self.generate_assessment(state)\n",
    "\n",
    "        # PDF\n",
    "        state.pdf_path_out = self.generate_pdf(state)\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLI / usage example\n",
    "# -------------------------\n",
    "def main():\n",
    "    # Basic choice: run from external JSON or a PDF file\n",
    "    print(\"Run pipeline from: 1) External JSON  2) PDF file\")\n",
    "    choice = input(\"Choose 1 or 2: \").strip()\n",
    "    use_audio = True  # safe default; change to True if audio libs present and you want voice\n",
    "    orchestrator = Orchestrator(use_audio=use_audio)\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Example: load pre-parsed JSON from a file path or paste inline\n",
    "        json_path = input(\"Path to external JSON (or leave blank to use sample): \").strip()\n",
    "        if not json_path:\n",
    "            print(\"Using sample placeholder. Replace with your `f1` object or path to your JSON file.\")\n",
    "            # Below is just a sample - Use the proper placeholders, whichever are needed\n",
    "            sample_f1 = {\n",
    "                \"message\": \"Resume uploaded and text extracted successfully.\",\n",
    "                \"resumeProfile\": {\n",
    "                    \"extracted_text\": \"John Doe ... resume text ...\",\n",
    "                    \"chunks\": [\"John Doe ... resume text ...\"]\n",
    "                }\n",
    "            }\n",
    "            resume_json = sample_f1\n",
    "        else:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "                resume_json = json.load(fh)\n",
    "\n",
    "        state = orchestrator.run_full_pipeline_from_json(resume_json)\n",
    "\n",
    "    else:\n",
    "        pdf_path = input(\"Path to resume PDF: \").strip()\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(\"File not found:\", pdf_path)\n",
    "            return\n",
    "        state = orchestrator.run_full_pipeline_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"\\n=== FINAL OUTPUTS ===\")\n",
    "    print(\"Profile:\")\n",
    "    print(json.dumps(state.profile, indent=2))\n",
    "    print(\"\\nTranscript:\")\n",
    "    for qa in state.transcript:\n",
    "        print(\"Q:\", qa[\"q\"])\n",
    "        print(\"A:\", qa[\"a\"])\n",
    "        print(\"-\" * 40)\n",
    "    print(\"\\nAssessment:\")\n",
    "    print(json.dumps(state.assessment, indent=2))\n",
    "    print(\"\\nPDF:\", state.pdf_path_out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f45dd69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run pipeline from: 1) External JSON  2) PDF file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample placeholder. Replace with your `f1` object or path to your JSON file.\n",
      "[extract_from_external_json] Running structured LLM extraction...\n",
      "\n",
      "\n",
      "[run_interview_loop] Starting interview for John (Mid)\n",
      "[run_interview_loop] Total Questions: 10\n",
      "\n",
      "\n",
      "============================================================\n",
      "‚ùì Question 1/10\n",
      "Interviewer: Hi John, to start off, can you tell me a bit about yourself and your experience so far in your mid-level role?\n",
      "\n",
      "How would you like to answer?\n",
      "1) Speak into microphone\n",
      "2) Type answer\n",
      "\n",
      "üõë Interview Stopped.\n",
      "\n",
      "Interview completed.\n",
      "\n",
      "[generate_assessment] Invoking assessor chain...\n",
      "[generate_pdf] PDF saved: candidate_assessment_John.pdf\n",
      "\n",
      "=== FINAL OUTPUTS ===\n",
      "Profile:\n",
      "{\n",
      "  \"candidate_first_name\": \"John\",\n",
      "  \"candidate_last_name\": \"Doe\",\n",
      "  \"candidate_email\": \"\",\n",
      "  \"candidate_linkedin\": \"\",\n",
      "  \"experience\": \"\",\n",
      "  \"skills\": [],\n",
      "  \"seniority_level\": \"Mid\"\n",
      "}\n",
      "\n",
      "Transcript:\n",
      "\n",
      "Assessment:\n",
      "{\n",
      "  \"candidate_score_percent\": \"40\",\n",
      "  \"hiring_recommendation\": \"Dont hire\",\n",
      "  \"strengths\": [\n",
      "    \"Calm demeanor\",\n",
      "    \"Clear and concise communication\"\n",
      "  ],\n",
      "  \"improvement_areas\": [\n",
      "    \"Lacked technical knowledge\",\n",
      "    \"Did not demonstrate relevant skills or experience\",\n",
      "    \"Unable to provide examples of past work\"\n",
      "  ],\n",
      "  \"next_steps\": \"Consider providing detailed feedback to the candidate about the lack of demonstrated skills and suggest gaining more experience before reapplying.\"\n",
      "}\n",
      "\n",
      "PDF: candidate_assessment_John.pdf\n"
     ]
    }
   ],
   "source": [
    "# Code using extracted information from pdf externally(Thereby reducing token usage on llm and agent) \n",
    "# Use this version(effect from 10th December 2025)\n",
    "\n",
    "\"\"\"\n",
    "orchestrator_from_json.py\n",
    "Full merged orchestrator that uses externally-parsed resume JSON (f1) as input.\n",
    "Features:\n",
    "- LLM-based structured extraction from provided resume text\n",
    "- FAISS vectorstore from provided chunks\n",
    "- TTS (gTTS) + STT (sounddevice + SpeechRecognition) optional per-question\n",
    "- Interview loop, structured assessment, PDF export\n",
    "- Two runners: from JSON (preferred) and from PDF (fallback)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "from typing import Any, Dict, List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LLM / embeddings / chain primitives\n",
    "try:\n",
    "    from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain_core.output_parsers import StrOutputParser\n",
    "    from langchain_core.documents import Document\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    from langchain_community.document_loaders import PyPDFLoader\n",
    "except Exception as e:\n",
    "    print(\"Warning: LangChain/OpenAI imports failed. Install required packages if you plan to run LLM steps.\")\n",
    "    print(\"Import error:\", e)\n",
    "\n",
    "# Audio & PDF generation\n",
    "AUDIO_AVAILABLE = True\n",
    "try:\n",
    "    from gtts import gTTS\n",
    "    from playsound3 import playsound\n",
    "    import speech_recognition as sr\n",
    "    import sounddevice as sd\n",
    "    import numpy as np\n",
    "    from scipy.io.wavfile import write\n",
    "except Exception as e:\n",
    "    AUDIO_AVAILABLE = False\n",
    "    print(\"Audio libs missing or failed to import ‚Äî audio features disabled. Error:\", e)\n",
    "\n",
    "try:\n",
    "    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "    from reportlab.lib.styles import getSampleStyleSheet\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.lib.units import inch\n",
    "except Exception as e:\n",
    "    print(\"Warning: reportlab not installed. PDF generation will fail. Error:\", e)\n",
    "\n",
    "# -------------------------\n",
    "# User-provided structured extraction schema\n",
    "# -------------------------\n",
    "class ResumeProfileExtraction(BaseModel):\n",
    "    name: Optional[str] = Field(description=\"Name of the candidate.\")\n",
    "    phone: Optional[str] = Field(description=\"Phone number of the candidate.\")\n",
    "    linkedin: Optional[str] = Field(description=\"LinkedIn Profile of the candidate.\")\n",
    "    github: Optional[str] = Field(description=\"GitHub link of the candidate.\")\n",
    "    skills: Optional[List[str]] = Field(description=\"Skills of the candidate.\")\n",
    "    experience: Optional[str] = Field(description=\"Candidate's work experience.\")\n",
    "\n",
    "\n",
    "# Structured assessment schema (same as before)\n",
    "class InterviewAssessment(BaseModel):\n",
    "    candidate_score_percent: str = Field(description=\"Score for the candidate out of 100.\")\n",
    "    hiring_recommendation: str = Field(description=\"Hiring recommendation: 'Definitely Hire!', 'Proceed with caution', 'Dont hire'\")\n",
    "    strengths: List[str] = Field(description=\"Strengths the candidate displayed.\")\n",
    "    improvement_areas: List[str] = Field(description=\"Improvement areas.\")\n",
    "    next_steps: str = Field(description=\"Suggested next steps.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Orchestrator state and prompts\n",
    "# -------------------------\n",
    "class InterviewState(BaseModel):\n",
    "    source_id: str  # \"JSON\" or PDF path\n",
    "    profile: Optional[Dict[str, Any]] = None\n",
    "    vectorstore: Optional[Any] = None\n",
    "    transcript: List[Dict[str, str]] = []\n",
    "    questions_asked: int = 0\n",
    "    max_questions: int = 0\n",
    "    assessment: Optional[Dict[str, Any]] = None\n",
    "    pdf_path_out: Optional[str] = None\n",
    "\n",
    "\n",
    "# Interviewer prompt (uses prompt template variables)\n",
    "interviewer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    The candidate has a seniority of: {seniority_level}.\n",
    "\n",
    "    YOUR PRIMARY GOAL:\n",
    "    - Conduct an interview of exactly {max_questions} questions.\n",
    "    - Match question difficulty to seniority level:\n",
    "        Fresher -> conceptual basics\n",
    "        Junior -> practical + scenario\n",
    "        Mid-level -> deeper practical reasoning\n",
    "        Senior -> architecture & ownership\n",
    "    SECONDARY GOAL:\n",
    "    - Ask a balanced variety: experience-based, skill-based, behavioral.\n",
    "    RULE:\n",
    "    - If total_questions_asked == 0, ask an introductory question (e.g., \"Tell me about yourself.\")\n",
    "    \"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    INTERVIEW STATUS:\n",
    "    Questions Asked: {total_questions_asked} / {max_questions}\n",
    "\n",
    "    TRANSCRIPT SO FAR:\n",
    "    {chat_history}\n",
    "\n",
    "    PROFILE CONTEXT:\n",
    "    {profile_context}\n",
    "\n",
    "    INSTRUCTION:\n",
    "    Generate *only* the next question. Avoid repeating earlier questions. Cover a new area if possible.\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# Assessment prompt\n",
    "assessment_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    You are an experienced Hiring Manager and Technical Assessor. Analyze the interview transcript and the candidate profile and generate a structured assessment JSON conforming to the InterviewAssessment schema.\n",
    "    \"\"\"),\n",
    "    (\"human\", \"\"\"\n",
    "    CANDIDATE PROFILE:\n",
    "    {profile_doc}\n",
    "\n",
    "    --- COMPLETE INTERVIEW TRANSCRIPT ---\n",
    "    {chat_history}\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Token Usage Implementation\n",
    "# -------------------------\n",
    "\n",
    "class TokenTracker:\n",
    "    def __init__(self):\n",
    "        self.total_input = 0\n",
    "        self.total_output = 0\n",
    "        self.calls = []\n",
    "\n",
    "    def add(self, response):\n",
    "        usage = response.usage_metadata or {}\n",
    "        self.total_input += usage.get(\"input_tokens\",0)\n",
    "        self.total_output += usage.get(\"output_tokens\",0)\n",
    "        self.calls.append(usage)\n",
    "        return response    \n",
    "\n",
    "# -------------------------\n",
    "# Orchestrator implementation\n",
    "# -------------------------\n",
    "class Orchestrator:\n",
    "    def __init__(self, llm: Optional[ChatOpenAI] = None, embeddings: Optional[OpenAIEmbeddings] = None, use_audio: bool = False):\n",
    "        self.llm = llm or (ChatOpenAI(model=\"gpt-4.1-mini\") if \"ChatOpenAI\" in globals() else None)\n",
    "        self.embeddings = embeddings or (OpenAIEmbeddings() if \"OpenAIEmbeddings\" in globals() else None)\n",
    "        self.use_audio = use_audio and AUDIO_AVAILABLE\n",
    "        self.token_tracker = TokenTracker()\n",
    "        self.interviewer_prompt = interviewer_prompt\n",
    "\n",
    "    # ---------- Audio helpers ----------\n",
    "    def _speak(self, text: str):\n",
    "        if not (AUDIO_AVAILABLE and self.use_audio):\n",
    "            return\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as tmp:\n",
    "            try:\n",
    "                tts = gTTS(text=text, lang=\"en\")\n",
    "                tts.save(tmp.name)\n",
    "                playsound(tmp.name)\n",
    "            finally:\n",
    "                try:\n",
    "                    os.remove(tmp.name)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    def _listen_for_answer(self, duration: int = 8, sample_rate: int = 16000, channels: int = 1) -> Optional[str]:\n",
    "        if not (AUDIO_AVAILABLE and self.use_audio):\n",
    "            return None\n",
    "        try:\n",
    "            print(f\"[STT] Recording for {duration}s...\")\n",
    "            recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=channels, dtype='float64')\n",
    "            sd.wait()\n",
    "            audio_int16 = np.int16(recording * 32767)\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "                write(tmp.name, sample_rate, audio_int16)\n",
    "                tmpfile = tmp.name\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.AudioFile(tmpfile) as source:\n",
    "                audio = recognizer.record(source)\n",
    "                text = recognizer.recognize_google(audio)\n",
    "            try:\n",
    "                os.remove(tmpfile)\n",
    "            except Exception:\n",
    "                pass\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(\"[STT] Error:\", e)\n",
    "            return None\n",
    "\n",
    "    # ---------- LLM-based structured extraction from text using provided schema ----------\n",
    "    def _llm_extract_profile(self, text: str) -> ResumeProfileExtraction:\n",
    "        if not self.llm:\n",
    "            raise RuntimeError(\"LLM not configured for profile extraction.\")\n",
    "        structured = self.llm.with_structured_output(ResumeProfileExtraction)\n",
    "        prompt = f\"\"\"\n",
    "Extract the following fields as clearly as possible from the text below:\n",
    "- Full name\n",
    "- Phone Number\n",
    "- LinkedIn\n",
    "- GitHub\n",
    "- Skills (as a list)\n",
    "- Experience (short summary)\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\"\"\"\n",
    "        print()\n",
    "        return structured.invoke(prompt)\n",
    "\n",
    "    # ---------- Build vectorstore from provided chunks ----------\n",
    "    def _build_vectorstore_from_chunks(self, chunks: List[str]):\n",
    "        docs = [Document(page_content=c, metadata={\"source\": \"external_chunk\", \"chunk_index\": i}) for i, c in enumerate(chunks)]\n",
    "        if not self.embeddings:\n",
    "            print(\"[_build_vectorstore_from_chunks] No embeddings configured; skipping vectorstore build.\")\n",
    "            return None\n",
    "        try:\n",
    "            vs = FAISS.from_documents(documents=docs, embedding=self.embeddings)\n",
    "            return vs\n",
    "        except Exception as e:\n",
    "            print(\"[_build_vectorstore_from_chunks] FAISS build failed:\", e)\n",
    "            return None\n",
    "\n",
    "    # ---------- New: Use external JSON (f1) as input ----------\n",
    "    def extract_from_external_json(self, resume_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # resume_json shape expected like your f1\n",
    "        if \"resumeProfile\" not in resume_json:\n",
    "            raise ValueError(\"resume_json must contain 'resumeProfile' key.\")\n",
    "\n",
    "        rp = resume_json[\"resumeProfile\"]\n",
    "        extracted_text = rp.get(\"extracted_text\", \"\")\n",
    "        chunks = rp.get(\"chunks\", [extracted_text])  # fallback to full text chunk if no chunks provided\n",
    "\n",
    "        # LLM structured extraction from the full extracted_text\n",
    "        try:\n",
    "            print(\"[extract_from_external_json] Running structured LLM extraction...\")\n",
    "            structured_result = self._llm_extract_profile(extracted_text)\n",
    "        except Exception as e:\n",
    "            print(\"[extract_from_external_json] Structured extraction failed:\", e)\n",
    "            # Build a minimal profile fallback\n",
    "            structured_result = ResumeProfileExtraction(name=None, phone=None, linkedin=None, github=None, skills=None, experience=None)\n",
    "\n",
    "        # Map to internal profile shape\n",
    "        name = (structured_result.name or \"\").strip()\n",
    "        first, last = (name.split(\" \", 1) + [\"\"])[:2] if name else (\"\", \"\")\n",
    "        profile = {\n",
    "            \"candidate_first_name\": first,\n",
    "            \"candidate_last_name\": last,\n",
    "            \"candidate_email\": rp.get(\"email\", \"\") or \"\",  # optional - your f1 may not provide explicit email field\n",
    "            \"candidate_linkedin\": structured_result.linkedin or rp.get(\"linkedin\", \"\"),\n",
    "            \"experience\": structured_result.experience or \"\",\n",
    "            \"skills\": structured_result.skills or [],\n",
    "            \"seniority_level\": \"Mid\"  # default; you could infer from experience/years if desired\n",
    "        }\n",
    "\n",
    "        vectorstore = self._build_vectorstore_from_chunks(chunks)\n",
    "        return {\"profile\": profile, \"vectorstore\": vectorstore, \"raw_chunks\": chunks, \"structured_result\": structured_result}\n",
    "\n",
    "    # ---------- (Optional) Small PDF fallback extractor if you still want to parse PDF ----------\n",
    "    def extract_from_pdf(self, pdf_path: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            resume_text = \"\\n\".join([p.page_content for p in pages])\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load PDF: {e}\")\n",
    "        # minimal chunks: split by pages\n",
    "        chunks = [p.page_content for p in pages]\n",
    "        return self.extract_from_external_json({\"resumeProfile\": {\"extracted_text\": resume_text, \"chunks\": chunks}})\n",
    "\n",
    "    # ---------- Interview loop (uses vectorstore for RAG context) ----------\n",
    "    def run_interview_loop(self, state: InterviewState):\n",
    "        \"\"\"Interview loop with TTS (gTTS) + STT (sounddevice) + optional typed answers.\"\"\"\n",
    "\n",
    "        # Determine max questions based on seniority\n",
    "        # Kept it experimental => can be changed accordingly\n",
    "        seniority = state.profile.get(\"seniority_level\", \"mid\").lower()\n",
    "        if seniority == \"fresher\":\n",
    "            max_q = 5\n",
    "        elif seniority == \"junior\":\n",
    "            max_q = 7\n",
    "        else:\n",
    "            max_q = 10\n",
    "        state.max_questions = max_q # Pushing max number of questions in state\n",
    "\n",
    "        print(f\"\\n[run_interview_loop] Starting interview for {state.profile.get('candidate_first_name', 'Candidate')} ({state.profile.get('seniority_level')})\")\n",
    "        print(f\"[run_interview_loop] Total Questions: {state.max_questions}\\n\")\n",
    "\n",
    "        while state.questions_asked < state.max_questions:\n",
    "\n",
    "            # Build chat-history for LLM\n",
    "            chat_history_text = \"\\n\".join(\n",
    "                [f\"Interviewer: {qa['q']}\\nCandidate: {qa['a']}\" for qa in state.transcript]\n",
    "            )\n",
    "\n",
    "            profile_context = json.dumps(state.profile, indent = 2)\n",
    "            \n",
    "            inputs = {\n",
    "                \"seniority_level\": state.profile[\"seniority_level\"],\n",
    "                \"total_questions_asked\": state.questions_asked,\n",
    "                \"max_questions\": state.max_questions,\n",
    "                \"chat_history\": chat_history_text,\n",
    "                \"profile_context\": json.dumps(state.profile, indent = 2)\n",
    "            }\n",
    "\n",
    "            # Generate question\n",
    "            try:\n",
    "                interview_chain = self.interviewer_prompt | self.llm | StrOutputParser() # Defining the interview chain\n",
    "                question = interview_chain.invoke(inputs) # Invoking the chain\n",
    "            except Exception as e:\n",
    "                print(\"[run_interview_loop] LLM failed, fallback question used.\")\n",
    "                question = f\"[Fallback] Please tell me about your experience. (Q{state.questions_asked+1})\"\n",
    "                 \n",
    "            qnum = state.questions_asked + 1 # Incrementing the question count by 1\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"‚ùì Question {qnum}/{state.max_questions}\")\n",
    "            print(\"Interviewer:\", question)\n",
    "\n",
    "            # Speak question via TTS\n",
    "            if AUDIO_AVAILABLE:\n",
    "                try:\n",
    "                    self._speak(question)\n",
    "                except Exception as e:\n",
    "                    print(\"[TTS Error]:\", e)\n",
    "            \n",
    "            # After speaking question, the user will have 2 options => either to type the answer, or to speak the answer.\n",
    "            # ---------------------------------------------\n",
    "            # USER CHOICE: SPEAK or TYPE\n",
    "            # ---------------------------------------------\n",
    "            print(\"\\nHow would you like to answer?\")\n",
    "            print(\"1) Speak into microphone\")\n",
    "            print(\"2) Type answer\")\n",
    "            method = input(\"Choose 1 or 2: \").strip()\n",
    "\n",
    "            answer = None\n",
    "\n",
    "            if method == \"1\" and AUDIO_AVAILABLE:\n",
    "                print(\"\\nüé§ Recording your answer...\")\n",
    "                answer = self._listen_for_answer(duration=12)\n",
    "\n",
    "                if not answer:\n",
    "                    print(\"‚ö†Ô∏è Speech recognition failed.\")\n",
    "                    answer = input(\"Please type your answer instead: \").strip()\n",
    "\n",
    "            else:\n",
    "                answer = input(\"\\nType your answer: \").strip()\n",
    "\n",
    "            if answer.lower() in (\"exit\", \"quit\"):\n",
    "                print(\"\\nüõë Interview Stopped.\")\n",
    "                break\n",
    "\n",
    "            # Save to transcript\n",
    "            state.transcript.append({\"q\": question, \"a\": answer})\n",
    "            state.questions_asked += 1\n",
    "\n",
    "        print(\"\\nInterview completed.\")\n",
    "        return state\n",
    "\n",
    "    # ---------- Assessment (route dict -> prompt -> structured LLM) ----------\n",
    "    def generate_assessment(self, state: InterviewState) -> Dict[str, Any]:\n",
    "        if not self.llm:\n",
    "            raise RuntimeError(\"LLM not configured for assessment.\")\n",
    "\n",
    "        structured_assessor = self.llm.with_structured_output(InterviewAssessment)\n",
    "        chain = assessment_prompt | structured_assessor\n",
    "\n",
    "        final_inputs = {\n",
    "            \"difficulty_level\": state.profile.get(\"seniority_level\", \"Mid\"),\n",
    "            \"profile_doc\": json.dumps(state.profile, indent=2),\n",
    "            \"chat_history\": \"\\n\".join([f\"Q: {t['q']}\\nA: {t['a']}\" for t in state.transcript])\n",
    "        }\n",
    "\n",
    "        print(\"\\n[generate_assessment] Invoking assessor chain...\")\n",
    "        try:\n",
    "            assessment_obj = chain.invoke(final_inputs)  # correct: passes dict to prompt template\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Assessment generation failed: {e}\")\n",
    "\n",
    "        assessment_dict = {\n",
    "            \"candidate_score_percent\": assessment_obj.candidate_score_percent,\n",
    "            \"hiring_recommendation\": assessment_obj.hiring_recommendation,\n",
    "            \"strengths\": assessment_obj.strengths,\n",
    "            \"improvement_areas\": assessment_obj.improvement_areas,\n",
    "            \"next_steps\": assessment_obj.next_steps\n",
    "        }\n",
    "        return assessment_dict\n",
    "\n",
    "    # ---------- PDF export ----------\n",
    "    def generate_pdf(self, state: InterviewState, filename: Optional[str] = None) -> str:\n",
    "        if filename is None:\n",
    "            filename = f\"candidate_assessment_{state.profile.get('candidate_first_name','candidate')}.pdf\"\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        title = Paragraph(f\"<b>Final Candidate Assessment for {state.profile.get('candidate_first_name','')} {state.profile.get('candidate_last_name','')}</b>\", styles[\"Title\"])\n",
    "        story.append(title)\n",
    "        story.append(Spacer(1, 0.25 * inch))\n",
    "        story.append(Paragraph(f\"<b>Overall Score:</b> {state.assessment.get('candidate_score_percent','N/A')}\", styles[\"Normal\"]))\n",
    "        story.append(Paragraph(f\"<b>Recommendation:</b> {state.assessment.get('hiring_recommendation','N/A')}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.15 * inch))\n",
    "        story.append(Paragraph(\"<b>Strengths:</b>\", styles[\"Heading3\"]))\n",
    "        for s in state.assessment.get(\"strengths\", []):\n",
    "            story.append(Paragraph(f\"‚Ä¢ {s}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.15 * inch))\n",
    "        story.append(Paragraph(\"<b>Improvement Areas:</b>\", styles[\"Heading3\"]))\n",
    "        for i in state.assessment.get(\"improvement_areas\", []):\n",
    "            story.append(Paragraph(f\"‚Ä¢ {i}\", styles[\"Normal\"]))\n",
    "        story.append(Spacer(1, 0.2 * inch))\n",
    "        story.append(Paragraph(\"<b>Next Steps:</b>\", styles[\"Heading3\"]))\n",
    "        story.append(Paragraph(state.assessment.get(\"next_steps\", \"\"), styles[\"Normal\"]))\n",
    "\n",
    "        pdf = SimpleDocTemplate(filename, pagesize=letter)\n",
    "        pdf.build(story)\n",
    "        print(f\"[generate_pdf] PDF saved: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    # ---------- Full-run entrypoints ----------\n",
    "    def run_full_pipeline_from_json(self, resume_json: Dict[str, Any]) -> InterviewState:\n",
    "        x = self.extract_from_external_json(resume_json)\n",
    "        state = InterviewState(source_id=\"EXTERNAL_JSON\")\n",
    "        state.profile = x[\"profile\"]\n",
    "        state.vectorstore = x[\"vectorstore\"]\n",
    "\n",
    "        # Interview loop\n",
    "        state = self.run_interview_loop(state)\n",
    "\n",
    "        # Assessment\n",
    "        state.assessment = self.generate_assessment(state)\n",
    "\n",
    "        # PDF\n",
    "        state.pdf_path_out = self.generate_pdf(state)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def run_full_pipeline_from_pdf(self, pdf_path: str) -> InterviewState:\n",
    "        x = self.extract_from_pdf(pdf_path)\n",
    "        state = InterviewState(source_id=pdf_path)\n",
    "        state.profile = x[\"profile\"]\n",
    "        state.vectorstore = x[\"vectorstore\"]\n",
    "\n",
    "        # Interview loop\n",
    "        state = self.run_interview_loop(state)\n",
    "\n",
    "        # Assessment\n",
    "        state.assessment = self.generate_assessment(state)\n",
    "\n",
    "        # PDF\n",
    "        state.pdf_path_out = self.generate_pdf(state)\n",
    "\n",
    "        return state\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLI / usage example\n",
    "# -------------------------\n",
    "def main():\n",
    "    # Basic choice: run from external JSON or a PDF file\n",
    "    print(\"Run pipeline from: 1) External JSON  2) PDF file\")\n",
    "    choice = input(\"Choose 1 or 2: \").strip()\n",
    "    use_audio = False  # safe default; change to True if audio libs present and you want voice\n",
    "    orchestrator = Orchestrator(use_audio=use_audio)\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # Example: load pre-parsed JSON from a file path or paste inline\n",
    "        json_path = input(\"Path to external JSON (or leave blank to use sample): \").strip()\n",
    "        if not json_path:\n",
    "            print(\"Using sample placeholder. Replace with your `f1` object or path to your JSON file.\")\n",
    "            # minimal sample structure ‚Äî replace with your actual `f1`\n",
    "            sample_f1 = {\n",
    "                \"message\": \"Resume uploaded and text extracted successfully.\",\n",
    "                \"resumeProfile\": {\n",
    "                    \"extracted_text\": \"John Doe ... resume text ...\",\n",
    "                    \"chunks\": [\"John Doe ... resume text ...\"]\n",
    "                }\n",
    "            }\n",
    "            resume_json = sample_f1\n",
    "        else:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "                resume_json = json.load(fh)\n",
    "\n",
    "        state = orchestrator.run_full_pipeline_from_json(resume_json)\n",
    "\n",
    "    else:\n",
    "        pdf_path = input(\"Path to resume PDF: \").strip()\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(\"File not found:\", pdf_path)\n",
    "            return\n",
    "        state = orchestrator.run_full_pipeline_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"\\n=== FINAL OUTPUTS ===\")\n",
    "    print(\"Profile:\")\n",
    "    print(json.dumps(state.profile, indent=2))\n",
    "    print(\"\\nTranscript:\")\n",
    "    for qa in state.transcript:\n",
    "        print(\"Q:\", qa[\"q\"])\n",
    "        print(\"A:\", qa[\"a\"])\n",
    "        print(\"-\" * 40)\n",
    "    print(\"\\nAssessment:\")\n",
    "    print(json.dumps(state.assessment, indent=2))\n",
    "    print(\"\\nPDF:\", state.pdf_path_out)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06c4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# Speed\n",
    "engine.setProperty('rate', 170)    # default ~200\n",
    "\n",
    "# Volume\n",
    "engine.setProperty('volume', 0.9)\n",
    "\n",
    "# Voice ‚Äî choose male/female depending on OS\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[1].id)  # try 0 or 1\n",
    "\n",
    "# Speak\n",
    "engine.say(\"Hello! I am python's available module, Thank you.\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e2a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
